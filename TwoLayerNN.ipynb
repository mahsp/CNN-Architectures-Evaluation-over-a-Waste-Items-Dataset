{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json, io, requests, string\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomDatasetFromImages(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            img_path (string): path to the folder where images are\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)\n",
    "        # First column contains the image paths\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
    "        # Second column is the labels\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
    "        # Third column is for an operation indicator\n",
    "        self.operation_arr = np.asarray(self.data_info.iloc[:, 2])\n",
    "        # Calculate len\n",
    "        self.data_len = len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        single_image_name = self.image_arr[index]\n",
    "        # Open image\n",
    "        img_as_img = Image.open(single_image_name)\n",
    "\n",
    "        # Check if there is an operation\n",
    "        some_operation = self.operation_arr[index]\n",
    "        # If there is an operation\n",
    "        if some_operation:\n",
    "            # Do some operation on image\n",
    "            # ...\n",
    "            # ...\n",
    "            pass\n",
    "        # Transform image to tensor\n",
    "        img_as_tensor = self.to_tensor(img_as_img)\n",
    "\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        single_image_label = self.label_arr[index]\n",
    "\n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "if __name__ == \"__main__\":\n",
    "    # Define transforms\n",
    "    \n",
    "    # Define custom dataset\n",
    "    train_data = CustomDatasetFromImages(\"Train0.csv\")\n",
    "    validation_data = CustomDatasetFromImages(\"Val0.csv\")\n",
    "    \n",
    "    # Define data loader\n",
    "#     trainset = torch.utils.data.DataLoader(dataset=train_data,\n",
    "#                                                     batch_size=100,\n",
    "#                                                     shuffle=True)\n",
    "    \n",
    "#     valset = torch.utils.data.DataLoader(dataset=validation_data,\n",
    "#                                                     batch_size=100,\n",
    "#                                                     shuffle=False)\n",
    "    \n",
    "    #for images, labels in trainset:\n",
    "        # Feed the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bachSize = 100\n",
    "class TwoLayerNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(TwoLayerNN, self).__init__()\n",
    "  \n",
    "    self.linear1 = nn.Linear(3 * 224 * 224, 512)\n",
    "    self.linear2 = nn.Linear(512, 6)\n",
    "        \n",
    "  def forward(self, x):\n",
    "    x = x.view(x.size(0), 3 * 224 * 224)\n",
    "    z = F.relu(self.linear1(x))\n",
    "    return self.linear2(z)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoLayerNN()\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.CustomDatasetFromImages'>\n",
      "328\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torch.optim as optim\n",
    "\n",
    "preprocessFn = transforms.Compose(\n",
    "    [transforms.Resize(224),  # 1. Resize smallest side to 256.\n",
    "     transforms.CenterCrop(224), # 2. Crop the center 224x224 pixels.\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean = [0.485, 0.456, 0.406],  # normalize.\n",
    "                          std = [0.229, 0.224, 0.225])])\n",
    "print(type(train_data))\n",
    "# img = []\n",
    "# labellist = []\n",
    "imgtensor = torch.zeros(1768,3,224,224)\n",
    "labeltensor = torch.LongTensor(1768,1).zero_()\n",
    "counter = 0\n",
    "for (i, (inputs, labels)) in enumerate(train_data):\n",
    "    counter += 1\n",
    "    art= transforms.ToPILImage()(inputs)\n",
    "    imgtensor[i,:,:,:] = preprocessFn(art).unsqueeze(0)\n",
    "#     print(labels)\n",
    "    labeltensor[i,:] = torch.tensor(labels)\n",
    "    \n",
    "imgtensorVal = torch.zeros(328,3,224,224)\n",
    "labeltensorVal = torch.LongTensor(328,1).zero_()\n",
    "counter = 0\n",
    "for (i, (inputs, labels)) in enumerate(validation_data):\n",
    "    counter += 1\n",
    "    art= transforms.ToPILImage()(inputs)\n",
    "    imgtensorVal[i,:,:,:] = preprocessFn(art).unsqueeze(0)\n",
    "#     print(labels)\n",
    "    labeltensorVal[i,:] = torch.tensor(labels)\n",
    "    \n",
    "print(counter)\n",
    "# Load the training, and validation datasets.\n",
    "trainset = train_data\n",
    "valset = validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# print(randomizer)\n",
    "\n",
    "train_accuracies = []; val_accuracies = []\n",
    "train_losses = []; val_losses = []\n",
    "\n",
    "trainset = torch.utils.data.TensorDataset(imgtensor, labeltensor)\n",
    "valset = torch.utils.data.TensorDataset(imgtensorVal, labeltensorVal)\n",
    "\n",
    "\n",
    "print(type(imgtensor))\n",
    "print(imgtensor[0].shape)\n",
    "\n",
    "def train_model(model, loss_fn, batchSize, trainset, valset, optimizer):\n",
    "  \n",
    "  # Shuffling is needed in case dataset is not shuffled by default.\n",
    "  train_loader = torch.utils.data.DataLoader(dataset = trainset,\n",
    "                                              batch_size = batchSize,\n",
    "                                              shuffle = True)\n",
    "#   # We don't need to bach the validation set but let's do it anyway.\n",
    "  val_loader = torch.utils.data.DataLoader(dataset = valset,\n",
    "                                             batch_size = batchSize,\n",
    "                                             shuffle = False) # No need.\n",
    "  \n",
    "  # Define number of epochs.\n",
    "  N = 5\n",
    "\n",
    "  # log accuracies and losses.\n",
    "  train_accuracies = []; val_accuracies = []\n",
    "  train_losses = []; val_losses = []\n",
    "\n",
    "  # GPU enabling.\n",
    "#   model = model.cuda()\n",
    "#   loss_fn = loss_fn.cuda()\n",
    "\n",
    "\n",
    "  # Training loop. Please make sure you understand every single line of code below.\n",
    "  # Go back to some of the previous steps in this lab if necessary.\n",
    "  for epoch in range(0, N):\n",
    "      correct = 0.0\n",
    "      cum_loss = 0.0\n",
    "\n",
    "      # Make a pass over the training data.\n",
    "      model.train()\n",
    "      for (i, (inputs, labels)) in enumerate(train_loader):\n",
    "          #print(type(inputs))\n",
    "#           inputs = inputs.cuda()\n",
    "#           labels = labels.cuda()\n",
    "          #print(inputs.shape)\n",
    "          #trans = transforms.ToPILImage()\n",
    "          #img = transforms.ToPILImage()(inputs)\n",
    "          #pil_img = trans(inputs)\n",
    "          #input_img =  preprocessFn(pil_img).unsqueeze(0)\n",
    "          # Forward pass. (Prediction stage)\n",
    "          scores = model(inputs)\n",
    "#           print(labels)\n",
    "          loss = loss_fn(scores, labels.view(-1))\n",
    "#           print(labels.view(-1))\n",
    "#           print(scores.shape)\n",
    "          # Count how many correct in this batch.\n",
    "          max_scores, max_labels = scores.max(1)\n",
    "#           print(max_labels)\n",
    "#           print(labels.view(-1))\n",
    "          correct += (max_labels == labels).sum().item()\n",
    "          cum_loss += loss.item()\n",
    "\n",
    "          # Zero the gradients in the network.\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          #Backward pass. (Gradient computation stage)\n",
    "          loss.backward()\n",
    "\n",
    "          # Parameter updates (SGD step) -- if done with torch.optim!\n",
    "          optimizer.step()\n",
    "          # Parameter updates (SGD step) -- if done manually!\n",
    "          # for param in model.parameters():\n",
    "          #   param.data.add_(-learningRate, param.grad)\n",
    "\n",
    "          # Logging the current results on training.\n",
    "          if (i + 1) % 1 == 0:\n",
    "              print('Train-epoch %d. Iteration %05d, Avg-Loss: %.4f, Accuracy: %.4f' % \n",
    "                    (epoch, i + 1, cum_loss / (i + 1), correct / ((i + 1) * batchSize)))\n",
    "\n",
    "\n",
    "      train_accuracies.append(correct / len(trainset))\n",
    "      train_losses.append(cum_loss / (i + 1))   \n",
    "\n",
    "      # Make a pass over the validation data.\n",
    "      correct = 0.0\n",
    "      cum_loss = 0.0\n",
    "      model.eval()\n",
    "      for (i, (inputs, labels)) in enumerate(val_loader):\n",
    "# #           inputs = inputs.cuda()\n",
    "# #           labels = labels.cuda()\n",
    "\n",
    "\n",
    "#           # Forward pass. (Prediction stage)\n",
    "           scores = model(inputs)\n",
    "           cum_loss += loss_fn(scores, labels.view(-1)).item()\n",
    "\n",
    "#            # Count how many correct in this batch.\n",
    "           max_scores, max_labels = scores.max(1)\n",
    "           correct += (max_labels == labels).sum().item()\n",
    "\n",
    "      val_accuracies.append(correct / len(valset))\n",
    "      val_losses.append(cum_loss / (i + 1))\n",
    "      \n",
    "      # Logging the current results on validation.\n",
    "      print('Validation-epoch %d. Avg-Loss: %.4f, Accuracy: %.4f' % \n",
    "            (epoch, cum_loss / (i + 1), correct / len(valset)))\n",
    "    \n",
    "  plt.figure(figsize = (10, 4))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.plot(val_losses, 'bo-', label = 'val-loss')\n",
    "  plt.plot(train_losses, 'ro-', label = 'train-loss') \n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch') \n",
    "  plt.legend(['validation', 'training'], loc='upper right')\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.plot(val_accuracies, 'bo-', label = 'val-acc')\n",
    "  plt.plot(train_accuracies, 'ro-', label = 'train-acc')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['validation', 'training'], loc='lower right')\n",
    "  plt.show()      \n",
    "\n",
    "\n",
    "      \n",
    "model = TwoLayerNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "# Create the model.\n",
    "# Optimizer.\n",
    "learningRate = 1e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr = learningRate)\n",
    "batchSize = 100\n",
    "\n",
    "train_model(model, loss_fn, batchSize, trainset, valset, optimizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
